\section{Abstract Limitations of Linear MOR}\label{sec:limitations-linear-mor}

This section is not directly linked to the systemtheoretic scope of this thesis, however it demonstrates an important motivation for the next chapter.
We thus think it reasonable to make a small detour and talk about the direct limitations of linear MOR for PDEs.
In effect, we want to transpose this motivation onto the problem inherent in this manuscript, however no such rigorous results as we present in this section are available as of the time of writing.

To make clear what we demonstrate here, we commence Subsection~\ref{subsec:pod} with the description of one of the standard techniques when reducing problem descriptions of PDEs without input or output variables: Proper Orthogonal Decomposition.
We then showcase a few model problems which serve as a good intuition on how the model we consider for reduction can impact the effectiveness of the reduction procedure in Subsection~\ref{subsec:kolmogorov-n-width}.

\itodo{think about removing the POD section, we don't really need it\dots}

\subsection{Proper Orthogonal Decomposition}\label{subsec:pod}

\itodo{this should be greedy, shouldn't it? Check sources for POD/greedy citaitons}

The first part of this section is heavily based upon~\cite{Pinnau2008}.
\emph{Proper Orthogonal Decomposition} (POD) is also known as Principal Component Analysis~\cite{Hotelling1936}, or Karhunen-LoÃ¨ve Decomposition~\cite{Karhunen1946}.
Its aim is the selection of a subspace through its basis such that the subspace optimally approximates the given data in the least-squares sense.
This basis is also commonly known as the \emph{POD modes}.
In Model Order Reduction this takes the concrete form of selecting a set of solutions $y_1, \dots, y_N$ of a PDE to use as basis functions for the reduced model.
To this end multiple strategies are available of which we present the method of snapshots in Subsubsection~\ref{subsubsec:pod-snapshots} and the singular value decomposition in Subsubsection~\ref{subsubsec:pod-svd}.

\subsubsection{Method of Snapshots}\label{subsubsec:pod-snapshots}

For a set of \emph{solution snapshots} $\iset{y_i \in \bb{R}^n}{i = 1, \dots, m, y_i = y(\mu_i)}$ of a parametrized PDE we construct the data matrix
\begin{equation}\label{eq:pod-data-matrix}
    Y = \left( y_1, \dots, y_N \right) \in \bb{R}^{n \times m}
\end{equation}
whose columns make up the individual snapshots $y_i$.
To compute the associated modes we have to solve the eigenvalue problems
\begin{equation*}
    \forall i = 1, \dots, n \colon\quad Y\herm Y v_i = \lambda_i v_i
\end{equation*}
for a set of orthonormal basis vectors $\iset{v_i \in \bb{R}^m}{i = 1, \dots, d}$.
The corresponding POD basis is then given as
\begin{equation*}
    u_i = \frac{1}{\sqrt{\lambda_i}} Y v_i.
\end{equation*}

\subsubsection{Singular Value Decomposition}\label{subsubsec:pod-svd}

Computing POD modes using the \emph{Singular Value Decomposition} (SVD) is closely linked to the method of snapshots in Subsubsection~\ref{subsubsec:pod-snapshots}.
We once more consider the data matrix $Y \in \bb{R}^{n \times m}$ from~\eqref{eq:pod-data-matrix}.
First, we compute the SVD of $Y$
\begin{equation*}
    Y = U \Sigma V\herm
\end{equation*}
for unitary matrices $U \in \bb{R}^{n \times n}, V \in \bb{R}^{m \times m}$ and the diagonal matrix $\Sigma = \diag{\sigma_1, \dots, \sigma_d, 0, \dots, 0}$ consisting of $d$ positive numbers $\sigma_1 \geq \cdots \geq \sigma_d > 0$.
We call the columns $u_i$ of $U$ and $v_i$ of $V$ left and right singular vectris to the singular values $\sigma_i$ respectively because they satisfy
\begin{equation*}
    Y v_i = \sigma_i u_i,\quad Y\herm u_i = \sigma_i v_i.
\end{equation*}
The POD basis then consists of the left singular vectors $u_i$.

\itodo{insert basic source on svd (consider those in~\cite{Pinnau2008}?)}

\subsection[The Kolmogorov N-Width]{The Kolmogorov {$N$}-Width}\label{subsec:kolmogorov-n-width}

With the POD basis computed we form a matrix similar in nature to~\eqref{eq:pod-data-matrix}
\begin{equation*}
    U = \left( u_1, \dots, u_d \right) \in \bb{R}^{n \times d}.
\end{equation*}
Using this matrix to project the full order space $\bb{R}^n$ onto the linear subspace $\bb{R}^d$ we can transform an exemplary linear system such as $A u = L$ with $A \in \bb{R}^{n \times n}, L \in \bb{R}^n$ to a reduced model by projecting the operators
\begin{equation*}
    \tilde{A} = U\trans A U,\quad \tilde{L} = U\trans L.
\end{equation*}

In practice, the matrix $U$ only serves as a projection onto a subspace with a much smaller dimension $d \ll n$ meaning that the resulting reduced solution $u_r$ will always introduce some error $\norm{u - u_r}{}$ with respect to the full order solution $u$ in some appropriate norm.
To bound the error of the reduced solutions we have to consider so-called N-widths; cf.~\cite{Pinkus1985}.
For linear approximations of problems defined on a parameter space $\mcl{P}$ we can provide an upper bound of the approximation quality of any reduced space $V_N$ with respect to the full order space $V$ by considering the \emph{Kolmogorov N-width} of a solution manifold $\mcl{M} = \iset{u(\mu)}{\mu \in \mcl{P}}$
\begin{equation}
    \kolm{\mcl{M}} \coloneqq \inf\limits_{\substack{V_N \subseteq V,\\\dim{(V_N)} = N}} \sup\limits_{v \in \mcl{M}} \inf\limits_{u_r \in V_N} \norm{v - u_r}{}.
\end{equation}
For the greedy algorithms, a specific subset of linear MOR techniqeus, a fast decay of the N-width is observed; cf.~\cite{Binev2011, DeVore2013}.
It can be shown that if the solutoins $u(\mu)$ depend analytically on $\mu$, then there exist constants $a, c > 0$ such that the Kolmogorov N-width can be bounded by
\begin{equation*}
    \kolm{\mcl{M}} \leq c \exp{(-N^\alpha)}.
\end{equation*}

However, not all problems exhibit this analytical solution manifold behaviour.
When considering advection dominated probles such as~\cite[Section~5.1]{Ohlberger2016} the upper bound on the Kolmogorov N-width instead turns into a lower bound limiting the decay
\begin{equation*}
    \kolm{\mcl{M}} \geq \frac{1}{2} N^{- \frac{1}{2}}.
\end{equation*}
Similarly, the hypberloic wave equation only decays with a lower bound of
\begin{equation*}
    \kolm{\mcl{M}} \geq \frac{1}{4} N^{- \frac{1}{2}}.
\end{equation*}
This slow decay becomes problematic when constructiong reduced models because one would require much larger reduced orders to make the error w.\ r.\ t.\ the full order model small enough.
The drawback of these increasing bases is the simultaneous increase in computational cost reducing the (online) speedup gained from reducing the model.
The consequence of these findings is immediate: To preserve the speedup obtained from order reduction we need to incorporate nonlinear parts into the reduced models.
We highlight some of these nonlinear approaches in Chapter~\ref{chap:nonlinear-mor}.
