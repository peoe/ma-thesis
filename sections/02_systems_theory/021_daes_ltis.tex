\section{Linear Time-Invariant Systems}\label{sec:ltis}

As detailed in~\cite{Kunkel2006}, a \emph{differential-algebraic equation} can be expressed as
\begin{equation}\label{eq:general-dae}
    F(t, x, \dot{x}) = 0,
\end{equation}
where for natural numbers $n, m$ the function $F \colon I \times \Omega_x \times \Omega_{\dot{x}} \to \bb{C}^m$ operates on an interval $I \sse \bb{R}$, and two open spatial domains $\Omega_x, \Omega_{\dot{X}} \sse \bb{C}^n$.
The source we referred to purposefully keeps the meaning of $\dot{x}$ ambiguous, referring to either the derivative with respect to time of a function $x$ or as an independent variable in the formulation.
For the purposes of this thesis however, we choose to only consider $\dot{x}$ to be the time derivative $\frac{\dif}{\dif t} x$.

In the case of linear DAEs with constant coefficients, we can express the implicit formulation of Equation~\eqref{eq:general-dae}
\begin{equation}\label{eq:lin-const-coeff-dae}
    E \dot{x}(t) = A x(t) + f(t)
\end{equation}
in terms of matrices $A, E \in \bb{C}^{n \times n}$ and a time dependent function $f \colon I \to \bb{C}^n$.
We further assume that the function $f$ serves as an influence on the solution of the DAE.\@
The interpretation here is that $f$ is a \emph{control} acting on the system over time.
We explicitly formulate the control in terms of yet another linear matrix product
\begin{equation}\label{eq:control-substitution}
    f(t) = B u(t)
\end{equation}
for some natural number $q$, a matrix $B \in \bb{C}^{n \times q}$, and a control variable $u \colon I \to \bb{C}^q$.
Lastly, we introduce an output component $y$ to our modelled system.
This output again takes the shape of a time dependent function $y \colon I \to \bb{C}^q$, and, keeping in line with Equaions~\eqref{eq:lin-const-coeff-dae} and~\eqref{eq:control-substitution}, we formulate it as the linear combination
\begin{equation}\label{eq:output-definition}
    y(t) = C x(t) + D u(t)
\end{equation}
for two matrices $C \in \bb{C}^{q \times n}, D \in \bb{C}^{q \times q}$.

\begin{definition}\label{def:lti}
    A \emph{linear time-invariant (descriptor) system} $\Sigma_{\msc{lti}}$ is a system of equations
    \begin{equation}\label{eq:lti}
        \Sigma_{\msc{lti}} \colon \left\lbrace
        \begin{aligned}
            E \dot{x}(t) &= A x(t) + B u(t), \\
            y(t) &= C x(t) + D u(t)
        \end{aligned}
        \right.
    \end{equation}
    with matrices $A, E \in \bb{C}^{n \times n}, B \in \bb{C}^{n \times q}, C \in \bb{C}^{q \times n}, D \in \bb{C}^{q \times q}$ constant in time, and state functions $x, \dot{x} \colon I \to \bb{C}^n$ and interaction variables $u, y \colon I \to \bb{C}^q$ varying over time.
\end{definition}

\begin{remark}
    Definition~\ref{def:lti} signifies a continuous dynamical system.
    If we instead sample the trajectory $x$ at fixed sample points $0 \leq t_1 \dots \leq t_k = T < \infty$, then we can formulate a dynamical system in discrete form
    \begin{equation*}
        \Sigma_{\msc{lti}}^{\msc{d}} \colon \left\lbrace
        \begin{aligned}
            E x_{i + 1} &= A x_i + B u_i, \\
            y_i &= C x_i + D u_i
        \end{aligned}
        \right.
    \end{equation*}
    where $x_i \coloneqq x(t_i)$ and $u_i \coloneqq u(t_i), y_i \coloneqq y(t_i)$ are the state, control, and output variables samples at the time points $t_i, i = 1, \dots, k$.
    In practice, these systems mostly come up when we either do not have the derivative data $\dot{x}_i \coloneqq \dot{x}(t_i)$ available to us or when we discretize a continuous system using a time stepping procedure.
\end{remark}

Any \ac{LTI} system in this form is said to act in the time domain, meaning that the inputs of both the \emph{states} $x, \dot{x}$, and the control $u$ and output variable $y$ are functions of time.
From a system theoretic point of view however it is necessary to also consider the system from the \emph{frequency domain}.
We thus describe the system not for a point in time, but rather for a certain frequency with which we excite the system.
We compute this frequency formulation by applying the \emph{Laplace transform}
\begin{equation*}\label{eq:laplace-trafo}
    \mcl{L}[f](\omega) = \int\limits_0^\infty \exp{(- \omega t)} f(t) \dif t
\end{equation*}
to the individual components in the \ac{LTI} system; cf.~\cite{Arendt2011}.
\begin{equation}
    X = \mcl{L}[x],\quad \dot{X} = \mcl{L}[\dot{x}],\quad U = \mcl{L}[u],\quad Y = \mcl{L}[y].
\end{equation}
As a crucial property, the Laplace transform of a derivative can be expressed as
\begin{equation*}
    \mcl{L}[\dot{x}](\omega) = \omega \mcl{L}[x](\omega) - \lim\limits_{t \searrow 0} x(t);
\end{equation*}
cf.~\cite[Theorem~9.1]{Doetsch1974}.
Therefore, under the assumption that the matrix pencil $\omega E - A$ is regular we compute from the first equation in~\eqref{eq:lti}
\begin{alignat*}{3}
     & & E \dot{X}(\omega) &= A X(\omega) + B U(\omega) \\
    \implies & & E (\omega X(\omega) - x(0)) &= A X(\omega) + B U(\omega) \\
    \implies & & \omega E X(\omega) - A X(\omega) &= E x(0) + B U(\omega) \\
    \implies & & (\omega E - A) X(\omega) &= E x(0) + B U(\omega) \\
    \implies & & X(\omega) &= (\omega E - A)\inv E x(0) + (\omega E - A)\inv B U(\omega).
\end{alignat*}
We apply this result to the second equation of the \ac{LTI} system~\eqref{eq:lti} thus describing the output in terms of the frequency-based control by the equation
\begin{equation}\label{eq:frequency-output}
    \begin{aligned}
        Y(\omega) &= C X(\omega) + D U(\omega) \\
        &= C (\omega E - A)\inv B U(\omega) + D U(\omega) + C (\omega E - A)\inv E x(0).
    \end{aligned}
\end{equation}
Notably, the last equality contains a summand which only depends on the initial state $x(0)$ of the system.
For ease of notation we assume that this initial value of the time domain state $x(t)$ is zero $x(0) = x_0 = 0$.
This restriction is a sensible assumption because it corresponds to a system that initially contains no energy and can only be interacted with through the outside control.
The reformulation~\eqref{eq:frequency-output} thus shows how we can directly compute the output of a system under influence of a control without having to consider the internal state representation.
More general definitions can also incorporate the initial state dependency in the transfer function, however we refer the reader to the introductory chapter in~\cite{Benner2017}.
We codify the control-output relation by defining the intermediate $\zeta$ such that $Y(\omega) = \zeta(\omega) U(\omega)$.

\begin{definition}\label{def:transfer-function}
    The \emph{transfer function} $\zeta \colon \bb{C} \to \bb{C}^{q \times q}$ of an \ac{LTI} system~\eqref{eq:lti} is defined by the expression
    \begin{equation}\label{eq:transfer-function}
        \zeta(\omega) = C (\omega E - A)\inv B + D
    \end{equation}
    for the system matrices $A, E \in \bb{C}^{n \times n}, B \in \bb{C}^{n \times q}, C \in \bb{C}^{q \times n}, D \in \bb{C}^{q \times q}$ and frequency domain control function $U \colon \bb{C} \to \bb{C}^{q}$.
\end{definition}

\begin{remark}
    The matrices $(A, B, C, D, E)$ used in the definition of the transfer function are not unique.
    For any transfer function multiple tuples of matrices may exist which induce the same transfer function.
    Any such tuple is called a \emph{realization} of the transfer function.
    We can create an arbitrary amount of realizaitons by considering the coordinate transformations $T \in \bb{C}^{n \times n}$.
    If $T$ is regular, then we can generate another realization of the transfer function $\zeta$ by substituting $\tilde{E} \coloneqq T E T\inv, \tilde{A} \coloneqq T A T\inv, \tilde{B} \coloneqq T B, \tilde{C} \coloneqq C T\inv$.
    The matrices $(\tilde{A}, \tilde{B}, \tilde{C}, D, \tilde{E})$ make up the same transfer function $\zeta$ when we compute
    \begin{align*}
        &C T\inv {\left( \omega T E T\inv - T A T\inv \right)}\inv T B + D \\
        =\ &C T\inv {\left( T (\omega E - A) T\inv \right)}\inv T B + D \\
        =\ &C T\inv T {\left( \omega E - A \right)}\inv T\inv T B + D \\
        =\ &C {(\omega E - A)}\inv B + D \\
        =\ &\zeta(\omega).
    \end{align*}
\end{remark}

\begin{remark}
    Besides the matrices themselves we can also come up with matrices of differing dimensions to represent the same transfer function.
    Consider a realization $(A, B, C, D, E)$ of the transfer function$\zeta$ and form the block matrices
    \begin{equation*}
        \tilde{A} \coloneqq \begin{pmatrix}
            A & 0 \\
            0 & 0
        \end{pmatrix},\quad \tilde{E} \coloneqq \begin{pmatrix}
            E & 0 \\
            0 & 0
        \end{pmatrix},\quad \tilde{C} \coloneqq \begin{pmatrix}
            C & 0
        \end{pmatrix},\quad \tilde{B} \coloneqq \begin{pmatrix}
            B \\
            0
        \end{pmatrix}.
    \end{equation*}
    When computing the transfer function we find that
    \begin{equation*}
        \tilde{C} {\left( \omega \tilde{E} - \tilde{A} \right)}\inv \tilde{B} + D = \zeta(\omega).
    \end{equation*}
\end{remark}

\begin{definition}[Cf.~\cite{CGH2022}]\label{def:minimal-system}
    The realization $(A, B, C, D, E)$ of the associated transfer function $\zeta$ is said to be \emph{minimal} if the number of states $n$ used in the realization is minimal.
\end{definition}

The transfer function of an \ac{LTI} system is an essential tool for constructing reduced order models.
We will discuss this further in Chapter~\ref{chap:linear-mor}, however we now introduce two key ideas for this later topic: stability of a system and the poles of a transfer function.
Following~\cite{Benner2017}, an \ac{LTI} system is called \emph{stable} if all the finite generalized eigenvalues of the matrix pencil $\omega E - A$ are contained in the left half of the complex plain $\bb{C}_{-} = \iset{\sigma \in \bb{C}}{\fk{Re}(\sigma) < 0}$.
Stable in this context refers to the fact that a solution for any stable system tends to zero for $t \rightarrow \infty$ as long as no control is applied ($u(t) \equiv 0$).
This property guarantees that a system is asymptotically stable.
Very closely connected to the eigenvalues of $\omega E - A$ are the poles of the transfer function associated with the realization $(A, B, C, D, E)$.
According to~\cite[Section~2]{Benner2017}, the transfer function $\zeta$ may be written as the rational expression
\begin{equation*}
    \zeta(\omega) = \frac{P(\omega)}{d(s)},
\end{equation*}
where $N$ is a matrix polynomial mapping to $\bb{C}^{q \times n}$ and $d$ is a scalar polynomial representing the least common denominator of all the $q \cdot n$ entries of $\zeta(\omega)$.

\begin{definition}\label{def:transfer-function-poles}
    Given a transfer function $\zeta = \frac{P(\omega)}{d(s)}$ we define its \emph{poles} as the set of complex numbers
    \begin{equation*}
        \mcl{P}(\zeta) \coloneqq \iset{\sigma \in \bb{C}}{d(\sigma) = 0}.
    \end{equation*}
    In general, the set of poles of the transfer function is a subset of the set of generalized eigenvectors of the matrix pencil $\omega E - A$, however if the realization $(A, B, C, D, E)$ is minimal, both sets are equal.
\end{definition}
