\chapter{Numerical Experiments}\label{chap:numerical-experiments}

In this chapter, we apply our procedure to a set of example problems.
The code to the individual experiments is available on GitHub\footnote{\href{https://www.github.com/peoe/quad-ph-mor}{github.com/peoe/quad-ph-mor}}.
In Section~\ref{sec:msd-systems} we commence with a model problem for the \ac{PHDMD} algorithm, the \ac{MSD} system.
Thereafter, we demonstrate the same procedure for the damped wave equation, showing how we can transform wave equations into \ac{PH} systems and testing our method on a more difficult problem in Section~\ref{sec:damped-wave-equation}.
For both models we compare the performance of the quadratic models inferred with \ac{PHDMD} from quadratically embedded control and output data to other, more basic and non-structure-preserving methods.
In doing so, we notice that the initialization strategy of the linear \ac{PHDMD} algorithm is not sophisticated enough to allow for large improvements in the performance of the underlying quadratic \ac{PH} models.

\section{Mass-Spring-Damper Systems}\label{sec:msd-systems}

In this section we discuss numerical experiments for an \ac{MSD} system.
In particular, we want to generalize the system from Example~\ref{ex:ms-system} to consist of a fixed number of mass, spring, and damper components arranged successively, closely following~\cite{Gugercin2012, Morandin2023}.
For our model problem, we consider a system containing $50$ mass-spring-damper pairs, resulting in a totel \ac{FOM} order of $100$.
Additionally, we introduce two separate controls that act on the first and the second mass, respectively, thus mimicking the model investigated in~\cite[Section~4.3]{Morandin2023}.

We apply the quadratic control and output adaptation of the \ac{PHDMD} algorithm described in Chapter~\ref{chap:quadratically-embedded-manifolds-ph-systems} to the \ac{MSD} system.
To compute the data used in the inference step we first simulate the \ac{FOM} for $1000$ time steps, a final time of $4$, and the following jump control variable
\begin{equation*}
    u(t) \coloneqq \begin{pmatrix}
        \mathbbm{1}_{t < \frac{1}{2}} \\
        - \mathbbm{1}_{t < \frac{1}{2}}
    \end{pmatrix},
\end{equation*}
where $\mathbbm{1}$ is the canonical indicator function, and obtain the full order data $X \in \bb{R}^{100 \times 1001}$ as well as $U, Y \in \bb{R}^{2 \times 1001}$.
Here, compared to the experiments in~\cite{Morandin2023}, we only use $1000$ time steps instead of $10000$ because, in addition to the linear model, we also have to infer a quadratic model with a significantly worse initialization when compared to the linear one.
This quadratic inference requires considerably more time, thus rendering the quadratic approach impractical for a large number of data points.
Moreover, we consider a jump type control variable in place of to the exponentially scaled sine wave
\begin{equation*}
    u(t) = \exp{(-t/2)} \begin{pmatrix}
        \sin{(t^2)} \\
        \cos{(t^2)}
    \end{pmatrix}
\end{equation*}
because we want to keep the control consistent between the \ac{MSD} and the damped wave equation experiments, which means that the wave would turn out much less interesting when observed in interaction with a smooth control without jumps.
Afterwards, we use \ac{POD} in order to reduce the state samples to $X \in \bb{R}^{r \times 1001}$, where $r \in \bb{N}$ is the corresponding intended reduced order of the linear \ac{ROM} $\Sigma_\msc{l}$.
Importantly, we obtain $1001$ data points because we also have an initial condition to consider; later in the application of the \ac{PHDMD} algorithm we average the data and thus reduce to the $1000$ data points used when inferring the models.
Next, we use the \ac{PHDMD} algorithm to infer a \ac{PH} \ac{LTI} system that serves as our fundamental linear \ac{ROM} $\Sigma_\msc{l}$.
In a similar way as with the \ac{FOM} we sample the linear system $\Sigma_\msc{l}$ and obtain the linear data $X_\msc{l} \in \bb{R}^{r \times 1001}, Y_\msc{l} \in \bb{R}^{2 \times 1001}$.
Penultimately, we calculate the quadratic fitting data $U_\msc{q}$ and $Y_\msc{q}$ by applying the Khatri--Rao product to both $U$ and the signed output error $Y - Y_\msc{l}$, resulting in
\begin{equation*}
    U_\msc{fit} \coloneqq U \odot U,\quad Y_\msc{fit} \coloneqq (Y - Y_\msc{l}) \odot (Y - Y_\msc{l}) \in \bb{R}^{3 \times 1001}.
\end{equation*}
Finally, the quadratic \ac{PH} system $\Sigma_\msc{q}$ is the result of applying \ac{PHDMD} with the internal combined data matrices $\mcl{T}$ and $\mcl{Z}$ obtained from the implicit midpoint procedure described in Equation~\eqref{eq:quad-fom-discrete-data}
\begin{equation*}
    \mcl{Z} \coloneqq \begin{pmatrix}
        E \dot{X_\msc{l}} \\
        -Y_\msc{fit}
    \end{pmatrix},\quad \mcl{T} \coloneqq \begin{pmatrix}
        X_\msc{l} \\
        U_\msc{fit}
    \end{pmatrix} \in \bb{R}^{(r + 3) \times 1000}.
\end{equation*}

To evaluate the performance of the inferred models we then construct the combined model $\Sigma_\msc{comb}$ as given in Equation~\eqref{eq:quad-io-system-coupling}.
To compare the results of both methods we additionally contrast them with models generated by using a simple \ac{OI} method derived from \ac{IODMD}.
For these models, analogously to the procedure using the \ac{PHDMD} algorithm, we first compute a baseline linear model and afterwards update it with an inferred quadratic model to obtain a combined model.
We compare the relative $\mcl{H}_\infty$ and $\mcl{H}_2$ errors with respect to the \ac{FOM} $\Sigma$, meaning that for the current reduced system $\Sigma_\msc{r}$ we compute
\begin{equation}\label{eq:rel-errors}
    \varepsilon_\infty \coloneqq \frac{\norm{\Sigma - \Sigma_\msc{r}}{\mcl{H}_\infty}}{\norm{\Sigma}{\mcl{H}_\infty}},\quad \varepsilon_2 \coloneqq \frac{\norm{\Sigma - \Sigma_\msc{r}}{\mcl{H}_2}}{\norm{\Sigma}{\mcl{H}_2}}.
\end{equation}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{.45 \textwidth}
        \begin{tikzpicture}[scale=.65, auto, swap]
            \begin{semilogyaxis}%
                [
                    scale only axis,
                    xmin = 1,
                    xmax = 21,
                    xtick distance = 2,
                    ymax = 1.05,
                    ytick distance = 10^(0.1),
                    tick pos = bottom,
                    xlabel = {Reduced Order $r$},
                    ylabel = {Rel. $\mcl{H}_\infty$ Error $\varepsilon_\infty$},
                    ylabel shift = 2pt,
                    cycle list name=exotic,
                    legend style={
                        legend cell align=left,
                    },
                    legend pos=north east,
                    legend style={nodes={scale=1.2, transform shape}},
                ]
                \addplot table[col sep=comma, x=ord, y=rlhinf]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{Linear}
                \addplot table[col sep=comma, x=ord, y=rqhinf]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{Combined}
            \end{semilogyaxis}
        \end{tikzpicture}
        \caption{Relative $\mcl{H}_\infty$ error comparison.}\label{fig:msd-lc-comp-hinf}
    \end{subfigure}%
    \begin{subfigure}[t]{.45 \textwidth}
        \begin{tikzpicture}[scale=.65, auto, swap]
            \begin{semilogyaxis}%
                [
                    scale only axis,
                    xmin = 1,
                    xmax = 21,
                    xtick distance = 2,
                    ymax = 1.1,
                    ytick distance = 10^(0.1),
                    tick pos = bottom,
                    xlabel = {Reduced Order $r$},
                    ylabel = {Rel. $\mcl{H}_2$ Error $\varepsilon_2$},
                    ylabel shift = 2pt,
                    cycle list name=exotic,
                    legend style={
                        legend cell align=left,
                    },
                    legend pos=north east,
                    legend style={nodes={scale=1.2, transform shape}},
                ]
                \addplot table[col sep=comma, x=ord, y=rlh2]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{Linear}
                \addplot table[col sep=comma, x=ord, y=rqh2]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{Combined}
            \end{semilogyaxis}
        \end{tikzpicture}
        \caption{Relative $\mcl{H}_2$ error comparison.}\label{fig:msd-lc-comp-h2}
    \end{subfigure}
    \caption{Comparison of relative $\mcl{H}_\infty$ and $\mcl{H}_2$ errors for linear \ac{PH} and combined linear-quadratic \ac{PH} models inferred using the \ac{PHDMD} algorithm.}\label{fig:msd-lc-comp}
\end{figure}

In Subfigure~\ref{fig:msd-lc-comp-hinf} we can see that while the approximation with the quadratic model is better when compared to the linear \ac{PH} \ac{ROM}, the improvement is only marginal and after a certain reduced order is surpassed, further improvements appear to stagnate.
The $\mcl{H}_2$ error in Subfigure~\ref{fig:msd-lc-comp-h2}, however, shows a completely different picture: the linear model achieves a much better result for decreasing orders before eventually plateauing below the quadratic model approximation error.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{.45 \textwidth}
        \begin{tikzpicture}[scale=.65, auto, swap]
            \begin{semilogyaxis}%
                [
                    scale only axis,
                    xmin = 1,
                    xmax = 21,
                    xtick distance = 2,
                    ymax = 1.1,
                    ytick distance = 10^1,
                    tick pos = bottom,
                    xlabel = {Reduced Order $r$},
                    ylabel = {Rel. $\mcl{H}_2$ Error $\varepsilon_2$},
                    ylabel shift = 2pt,
                    cycle list name=exotic,
                    legend style={
                        legend cell align=left,
                    },
                    legend pos=south west,
                    legend style={nodes={scale=1.2, transform shape}},
                ]
                \addplot table[col sep=comma, x=ord, y=rlh2]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{Linear}
                \addplot table[col sep=comma, x=ord, y=rqh2]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{Combined}
                \addplot+[mark=diamond*] table[col sep=comma, x=ord, y=rPHIRKAh2]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{\ac{PHIRKA}}
            \end{semilogyaxis}
        \end{tikzpicture}
        \caption{Comparison of relative $\mcl{H}_2$ errors for inferred linear and combined linear-quadratic \ac{PH} systems calculated with the \ac{PHDMD} algorithm and a linear model reduced with the intrusive \ac{PHIRKA} method.}\label{fig:msd-method-comp-intrusive}
    \end{subfigure}
    \begin{subfigure}[t]{.45 \textwidth}
        \begin{tikzpicture}[scale=.65, auto, swap]
            \begin{semilogyaxis}%
                [
                    scale only axis,
                    xmin = 1,
                    xmax = 21,
                    xtick distance = 2,
                    ytick distance = 10^(0.1),
                    tick pos = bottom,
                    xlabel = {Reduced Order $r$},
                    ylabel = {Rel. $\mcl{H}_2$ Error $\varepsilon_2$},
                    ylabel shift = 2pt,
                    cycle list name=exotic,
                    legend style={
                        legend cell align=left,
                    },
                    legend pos=north east,
                    legend style={nodes={scale=1.2, transform shape}},
                ]
                \addplot table[col sep=comma, x=ord, y=rqh2]{sections/06_numerical_experiments/msd/jump/msd_phdmd_err.csv};
                \addlegendentry{\ac{PHDMD}}
                \addplot table[col sep=comma, x=ord, y=rqh2]{sections/06_numerical_experiments/msd/jump/msd_oi_err.csv};
                \addlegendentry{\ac{OI}}
            \end{semilogyaxis}
        \end{tikzpicture}
        \caption{Comparison of relative $\mcl{H}_2$ errors for combined linear-quadratic systems inferred from the structure-preserving \ac{PHDMD} algorithm and an unstructured \ac{OI} method.}\label{fig:msd-method-comp-unstructured}
    \end{subfigure}
    \caption{Comparison between different methods for obtaining reduced linear and combined linear-quadratic systems for intrusive and data-driven, and unstructured and structure-preserving algorithms.}
\end{figure}

As expected, both data-driven inferred models pale in comparison to an intrusive \ac{MOR} technique such as \ac{PHIRKA}, which is apparent from Subfigure~\ref{fig:msd-method-comp-intrusive}.
The lack of system matrix information other than the one inferred from the provided sample data results in an overall worse performance for both the linear and the quadratic models calculated with \ac{PHDMD}.
When contrasting the \ac{PHDMD} inference approach with the \ac{OI}-based non-structure-preserving method, we observe in Subfigure~\ref{fig:msd-method-comp-unstructured} that the combined linear-quadratic model achieves comparable though slightly worse and far less stable results than the \ac{PHDMD} algorithm.
This difference is most likely due to the missing structural constraints and the coupled benefits such as the stability of the resulting problem.

\begin{table}[ht]
    \centering
    \begin{tabularx}{.925 \textwidth}{%
        >{\centering\arraybackslash}X|c|>{\centering\arraybackslash}X|>{\centering\arraybackslash}X%
        }
        \bfseries Method & \bfseries Order & \bfseries $t_\msc{l}$ in seconds & \bfseries $t_\msc{q}$ in seconds
        \csvreader[head to column names]{sections/06_numerical_experiments/msd/quad_state_comp.csv}{}%
        {\\\method & \ord & \ltime & \qtime}%
    \end{tabularx}
    \caption{Comparison of exemplary runtimes for linear and combined linear-quadratic models inferred using the \ac{PHDMD} algorithm; ``PHDMD'' denotes models based upon a quadratically embedded internal state variable, ``FrequencyPHDMD'' describes models with quadratically embedded control and output variables; $t_\msc{l}$ is the computational time for the linear \ac{PH} system, $t_\msc{q}$ stands for the computational time of the quadratic \ac{PH} model.}\label{tab:msd-time-comp}
\end{table}

Importantly, we do not compare the results of the quadratic models to those obtained from applying the \ac{PHDMD} algorithm to quadratic internal states because the runtime of \ac{PHDMD} and the obtained results were much worse than for the models with quadratically embedded control and output variables in our trial runs.
The table in Figure~\ref{tab:msd-time-comp} shows the times necessary to calculate both the linear and the quadratic \acp{ROM} with the \ac{PHDMD} algorithm for a small sample set of orders.
We note in particular that the scaling of the temporal needs of the inference step depends on the underlying dimensions of the input data.
Thus, the quadratically embedded control and output variables result in calculations that are much more consistent in their runtimes in contrast to the quadratically embedded internal states.

\begin{figure}[ht]
    \centering
    \begin{subfigure}[t]{.45 \textwidth}
        \begin{tikzpicture}[scale=.65, auto, swap]
            \begin{semilogyaxis}%
                [
                    scale only axis,
                    xmin = 1,
                    xmax = 11,
                    xtick distance = 2,
                    ymax = 1.1,
                    ytick distance = 10^(0.1),
                    tick pos = bottom,
                    xlabel = {Reduced Order $r$},
                    ylabel = {Rel. $\mcl{H}_\infty$ Error $\varepsilon_\infty$},
                    ylabel shift = 2pt,
                    cycle list name=exotic,
                    legend style={
                        legend cell align=left,
                    },
                    legend pos=north east,
                    legend style={nodes={scale=1.2, transform shape}},
                ]
                \addplot table[col sep=comma, x=ord, y=rlhinf]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Linear final}
                \addplot table[col sep=comma, x=ord, y=rilhinf]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Linear initial}
                \addplot+[mark=diamond*] table[col sep=comma, x=ord, y=rqhinf]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Combined final}
                \addplot+[mark=triangle*] table[col sep=comma, x=ord, y=riqhinf]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Combined initial}
            \end{semilogyaxis}
        \end{tikzpicture}
        \caption{Relative $\mcl{H}_\infty$ error comparison.}
    \end{subfigure}
    \begin{subfigure}[t]{.45 \textwidth}
        \begin{tikzpicture}[scale=.65, auto, swap]
            \begin{semilogyaxis}%
                [
                    scale only axis,
                    xmin = 1,
                    xmax = 11,
                    xtick distance = 2,
                    ymin = .4,
                    ytick distance = 10^(0.1),
                    tick pos = bottom,
                    xlabel = {Reduced Order $r$},
                    ylabel = {Rel. $\mcl{H}_2$ Error $\varepsilon_2$},
                    ylabel shift = 2pt,
                    cycle list name=exotic,
                    legend style={
                        legend cell align=left,
                    },
                    legend pos=south west,
                    legend style={nodes={scale=1.2, transform shape}},
                ]
                \addplot table[col sep=comma, x=ord, y=rlh2]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Linear final}
                \addplot table[col sep=comma, x=ord, y=rilh2]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Linear initial}
                \addplot+[mark=diamond*] table[col sep=comma, x=ord, y=rqh2]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Combined final}
                \addplot+[mark=triangle*] table[col sep=comma, x=ord, y=riqh2]{sections/06_numerical_experiments/msd/init_diff.csv};
                \addlegendentry{Combined initial}
            \end{semilogyaxis}
        \end{tikzpicture}
        \caption{Relative $\mcl{H}_2$ error comparison.}
    \end{subfigure}
    \caption{Comparison of relative $\mcl{H}_\infty$ and $\mcl{H}_2$ errors for initial and final realizations of linear and combined linear-quadratic models inferred with the \ac{PHDMD} algorithm.}\label{fig:msd-init-comp}
\end{figure}

Crucially, Figure~\ref{fig:msd-init-comp} shows that the initialization step in the \ac{PHDMD} algorithm is essential for the quality of the final model.
Whereas the linear model fluctuates noticeably depending on the initial matrices calculated from the weighted \ac{PHDMD} problem described in Equation~\eqref{eq:weighted-ph-dmd}, the combined linear-quadratic system exhibits only small changes after running the \ac{PHDMD} algorithm.
In combination with the mediocre results seen in Figure~\ref{fig:msd-lc-comp}, this hints at a larger underlying issue: the current weighted initialization may be suitable for the linear model inference problem posed in~\cite{Morandin2023} but it is insufficient for significant improvements with the more complex quadratically embedded data manifold setting that we follow.

\section{Damped Wave Equation}\label{sec:damped-wave-equation}

We also want to demonstrate the performance of our method on a system more complex than the \ac{MSD} model from Section~\ref{sec:msd-systems}.
To this end we consider the unit interval $\Omega = \interval{0}{1}$ as well as the temporal domain $I = \interval[open right]{0}{T}, T > 0$, and model a damped wave with the equation
\begin{equation}\label{eq:basic-damped-wave}
    \pd[t]{2} \omega + \alpha \pd[t]{} \omega = c^2 \lapl[\omega],
\end{equation}
where $\omega \colon \Omega \times I \to \bb{R}$ denotes the amplitude of our medium in space, $\lapl$ is the Laplace operator, $n \in \bb{R}$ is the unit outer normal of the spatial domain $\Omega$, and $\alpha, c > 0$ describe the damping coefficient and wave speed, respectively.
Obviously, Equation~\eqref{eq:basic-damped-wave} is not yet a \ac{PH} system.
In order to obtain a \ac{PH} formulation we follow the procedure given in~\cite{Serhani2019_2, HMS2022} in combination with the problems described in~\cite{Brugnoli2021, Poussot2023}.
Instead of discretizing the entire equation in terms of the local function $\omega$, we consider the following new state variables in its stead
\begin{equation*}
    v \coloneqq \pd[t]{} \omega,\quad w \coloneqq c^2 \nabla \omega.
\end{equation*}
Substituting these variables into the original damped wave equation~\eqref{eq:basic-damped-wave} we calculate
\begin{equation}\label{eq:substituted-damped-wave}
    \pd[t]{} v + \alpha v = \dvg{w}.
\end{equation}
Additionally, we consider the following trivial coupling between the two components $v$ and $w$
\begin{equation}\label{eq:relation-damped-wave}
    \frac{1}{c^2} \pd[t]{} w = \pd[t]{} \nabla \omega = \nabla \pd[t]{} \omega = \nabla v.
\end{equation}
To derive the control and the output of the whole system, we combine Equations~\eqref{eq:substituted-damped-wave} and~\eqref{eq:relation-damped-wave} into a single system of equations and, for an arbitrary test function $\varphi \in C_\msc{c}^\infty(\Omega)$, consider its weak formulation
\begin{equation*}
    \begin{aligned}
        \frac{1}{c^2} \inner{\pd[t]{} w}{\varphi}{} &= \inner{\nabla v}{\varphi}{}, \\
        \inner{\pd[t]{} v}{\varphi}{} &= \inner{\dvg{w}}{\varphi}{} - \alpha \inner{v}{\varphi}{},
    \end{aligned}
\end{equation*}
which we transform once more with the usual application of Green's formula to calculate
\begin{equation}\label{eq:weak-damped-wave}
    \begin{aligned}
        \frac{1}{c^2} \inner{\pd[t]{} w}{\varphi}{} &= \inner{\nabla v}{\varphi}{}, \\
        \inner{\pd[t]{} v}{\varphi}{} &= - \inner{w}{\nabla \varphi}{} + \inner{\inner{\res{w}{\partial \Omega}}{n}{}}{\varphi}{} - \alpha \inner{v}{\varphi}{}.
    \end{aligned}
\end{equation}
After defining $u \coloneqq \inner{\res{w}{\partial \Omega}}{n}{}$ and choosing an appropriate Finite Element discretization, we formulate the weak damped wave equation system~\eqref{eq:weak-damped-wave} as
\begin{equation}\label{eq:damped-wave-state}
    \begin{aligned}
        \frac{1}{c^2} \cdot M_w \pd[t]{} w &= D v, \\
        M_v \pd[t]{} v &= - D\trans w - \alpha \cdot C v + B u
    \end{aligned}
\end{equation}
with the vectorized state variables $w, v \in \bb{R}^n$, the control on the boundary $u \in \bb{R}^2$, and the system matrices $M_w, M_v, D \in \bb{R}^{n \times n}, B \in \bb{R}^{n \times 2}$.
We remark that the block matrices $G\trans = \begin{pmatrix}
    0 & B\trans
\end{pmatrix}$ and
\begin{equation}\label{eq:damped-wave-blocks}
    E \coloneqq
    \begin{tikzpicture}[baseline]
        \matrix[supermatrix, nodes=submatrix] {
            \frac{1}{c^2} M_w \&  \\
            \& M_v \\
        };
    \end{tikzpicture}
    ,\quad J =
    \begin{tikzpicture}[baseline]
        \matrix[supermatrix, nodes=submatrix] {
            \& D \\
            -D\trans \&  \\
        };
    \end{tikzpicture}
    ,\quad R =
    \begin{tikzpicture}[baseline]
        \matrix[supermatrix, nodes=submatrix] {
            0 \&  \\
            \& \alpha \cdot C \\
        };
    \end{tikzpicture}
\end{equation}
form the foundations of a \ac{PH} system.
As the final component of the \ac{PH} system we have to construct, we define its output by considering the structure~\eqref{eq:phlti} of any \ac{PH} system with a given matrix $G$ coupling the control to the internal states.
This results in the following last system equation as well as the immediate relation to the internal states
\begin{equation}\label{eq:damped-wave-output}
    y = G\trans \begin{pmatrix}
        w \\
        v
    \end{pmatrix},\quad y = \res{v}{\partial \Omega}.
\end{equation}
Ultimately, we can substitute the block matrices~\eqref{eq:damped-wave-blocks} into the system of equations~\eqref{eq:damped-wave-state} to obtain the state equation and combine this with the output relation in Equation~\eqref{eq:damped-wave-output} into the system
\begin{equation}\label{eq:damped-wave-ph}
    \Sigma_\msc{wave} \colon \left\lbrace
    \begin{aligned}
        E \pd[t]{} \begin{pmatrix}
            w \\
            v
        \end{pmatrix} &= (J - R) \begin{pmatrix}
            w \\
            v
        \end{pmatrix} + G u, \\
        y &= G\trans \begin{pmatrix}
            w \\
            v
        \end{pmatrix}.
    \end{aligned}
    \right.
\end{equation}

\begin{remark}
    The block matrix $R$ in Equation~\eqref{eq:damped-wave-blocks} is singular, which causes problems when simulating the model~\eqref{eq:damped-wave-ph} or when applying the \ac{PHDMD} algorithm to the system.
    We mitigate this issue by regularizing the upper left block such that we use
    \begin{equation}\label{eq:damped-wave-regularization}
        \tilde{R} =
        \begin{tikzpicture}[baseline]
            \matrix[supermatrix, nodes=submatrix] {
                \lambda \cdot \id \&  \\
                \& \alpha \cdot C \\
            };
        \end{tikzpicture}
    \end{equation}
    for some regularization parameter $\lambda > 0$ instead.
    For our simulations in particular we choose $\lambda = 2 \cdot 10^{-3}$ because this parameter yielded the best result among a set of fixed sample parameters we compared among each other.
\end{remark}

Similarly to the \ac{MSD} problem from Section~\ref{sec:msd-systems}, we first simulate the \ac{PH} \ac{FOM} of order $100$ representing the damped wave equation~\eqref{eq:damped-wave-ph} and reduce the computed internal states with \ac{POD}.
As before, we use the jump control
\begin{equation*}
    u(t) \coloneqq \begin{pmatrix}
        \mathbbm{1}_{t < \frac{1}{2}} \\
        - \mathbbm{1}_{t < \frac{1}{2}}
    \end{pmatrix}
\end{equation*}
because it is known that the Kolmogorov $N$-width of wave equations with jumps in their initial conditions cannot be bounded by an exponentially decaying term depending on the reduced order.
Thereafter, we follow the same process as with the \ac{MSD} model from before: we calculate a basic linear \ac{ROM} $\Sigma_\msc{l}$ with \ac{PHDMD}, sample the linear model $\Sigma_\msc{l}$, infer a quadratic \ac{ROM} $\Sigma_\msc{q}$ by applying the \ac{PHDMD} algorithm to the quadratic data $U_\msc{q}, Y_\msc{q} \in \bb{R}^{3 \times 1001}$, and finally assemble the combined model $\Sigma_\msc{comb}$ in accordance with the relations layed out in Equation~\eqref{eq:quad-io-system-coupling}.
Further, we once more construct comparable models from the \ac{OI} algorithm by first inferring a linear \ac{ROM} and afterwards updating it with a quadratic model to obtain a combined model.
As before, we compare the relative $\mcl{H}_2$ errors of the reduced models with respect to the $\mcl{H}_2$ norm of the \ac{FOM}, see Equation~\eqref{eq:rel-errors}.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[scale=.65, auto, swap]
        \begin{semilogyaxis}%
            [
                scale only axis,
                xmin = 1,
                xmax = 21,
                xtick distance = 2,
                ymin = 10^(-0.011),
                ytick = {10^0, 10^(-0.01)},
                tick pos = bottom,
                xlabel = {Reduced Order $r$},
                ylabel = {Rel. $\mcl{H}_2$ Error $\varepsilon_2$},
                ylabel shift = 2pt,
                cycle list name=exotic,
                legend style={
                    legend cell align=left,
                },
                legend pos=south west,
                legend style={nodes={scale=1.5, transform shape}},
            ]
            \addplot table[col sep=comma, x=ord, y=rlh2]{sections/06_numerical_experiments/wave1d/jump/wave1d_phdmd_err.csv};
            \addlegendentry{Linear}
            \addplot table[col sep=comma, x=ord, y=rqh2]{sections/06_numerical_experiments/wave1d/jump/wave1d_phdmd_err.csv};
            \addlegendentry{Combined}
        \end{semilogyaxis}
    \end{tikzpicture}
    \caption{Comparison of relative $\mcl{H}_2$ errors for linear and combined linear-quadratic models generated with the \ac{PHDMD} method and the linear intrusively constructed model from the \ac{PHIRKA} algorithm.}\label{fig:wave-methods-comp}
\end{figure}

Similarly to the \ac{MSD} experiment in Section~\ref{sec:msd-systems}, we do not compare the results of the quadratic models to ones calculated with \ac{PHDMD} applied to quadratic internal state variables because the scaling behaviour of the computation times is akin to the one presented for the \ac{MSD} model in Table~\ref{tab:msd-time-comp} and the results obtained in our trial runs were inferior to the ones presented here.

Analogously to the \ac{MSD} model, the initialization of the system matrices plays an important role.
Unlike in Section~\ref{sec:msd-systems}, however, both the linear and the combined model do not result in a satisfactory reduction of the error measures with respect to the \ac{FOM}.
To conclude this experiment, we reiterate the difficulties in constructing \ac{PH} models with quadratically embedded manifolds:
\begin{itemize}
    \item The results of the simulation rely on the regularization parameter introduced in Equation~\eqref{eq:damped-wave-regularization}, therefore requiring lots of hyper-parameter optimization.
    \item The quadratic data embeddings via the Kronecker and Khatri--Rao products are numerically ill-conditioned depending on the approximative quality of the underlying linear model.
    \item The initialization via the weighted \ac{PHDMD} problem~\eqref{eq:weighted-ph-dmd} is not adapted to respect quadratic data terms.
    \item The model's control variables can influence the quality of the final inferred model, because they directly link to the system's behaviour: in the case of the damped wave equation~\eqref{eq:damped-wave-ph} the jump control on the boundary results in similar observations as an initial condition containing a jump.
    \item Analogously to similar approaches for symplectic problems such as~\cite{Sharma2023}, certain parameter combinations can lead to the overfitting of the model on the provided data.
\end{itemize}
