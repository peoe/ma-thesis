\section{Quadratically Embedded Manifolds for \acl{PH} Systems}\label{sec:quadratically-embedded-manifolds-ph-systems}

In this section we discuss how we can construct quadratic \ac{PH} systems.
This construction is restricted by the terms we consider as quadratic terms, hence influencing our choices in modelling.
Most importantly, we want to create a model which preserves the control and output variable dimensions.
By thusly preserving parts of the structure, we can easily use an interconnection between the original linear system and the new quadratic model.
As a consequence, some of the system's components can remain unchanged, reducing the number of unknowns we have to acknowledge in the process.

We commence the construction with the usual description of a full order linear \ac{PH} system $\Sigma_\msc{ph}$ given by the system matrices
\begin{equation*}
    \begin{aligned}
        E \dot{x} &= (J - R) x + (G - P) u, \\
        y &= {(G + P)}\trans x + (S - N) u.
    \end{aligned}
\end{equation*}
Next, we follow one of the methods proposed in Section~\ref{sec:structure-preserving-mor} to construct a reduced order model $\hat{\Sigma}_\msc{ph} = (\hat{E}, \hat{J}, \hat{R}, \hat{G}, \hat{P}, \hat{N}, \hat{S})$.
The ultimate goal of fitting a quadratic system $\Sigma_\msc{ph}^\msc{q}$ is to minimize the error in the output.
This can be quantified by $\varepsilon(t) \coloneqq y_\msc{fom}(t) - y_\msc{rom}(t)$, the signed error of the \ac{ROM} output with respect to the \ac{FOM} output.
If we can fit a quadratic model such that the quadratic output models the signed error $y_\msc{quad}(t) = \varepsilon(t)$, then we can couple $\hat{\Sigma}_\msc{ph}$ and $\Sigma_\msc{ph}^\msc{q}$ by adding the individual outputs $y_\msc{total} = y_\msc{rom} + y_\msc{quad}$.
The objective of fitting $\Sigma_\msc{ph}^\msc{q}$ now consists of computing appropriate matrices $E^\msc{q}, J^\msc{q}, R^\msc{q}, G^\msc{q}, P^\msc{q}, N^\msc{q}, S^\msc{q}$ such that the quadratic transfer function $\mcl{H}^\msc{q}$ produces a good approximation of the signed linear output error.
Notationally, we once again use $U, Y$ to refer to the Laplace transforms of $u, y$ as in Section~\ref{sec:ltis}, as well as $\mcl{E}$ for the signed error.
Therefore, fitting $\Sigma^\msc{q}$ means choosing the system matrices in such a way that $\mcl{E}(\omega) = \mcl{H}^\msc{q}(\omega) U(\omega)$ is satisfied for a frequency parameter $\omega$.
In practice, this fit does not have to hold for all possible frequency ranges but rather for a select set of frequency domains depending on the problem and its underlying dynamic response.
This specifically influences the choice of how we come up with the system matrices, however we discuss this later on.

Besides the choice of procedure, using quadratic state variables also implies that we have to choose how to consider the $E^\msc{q}$ matrix in the quadratic system.
If $E^\msc{q}$ is chosen by computation from the linear system variables we get two options:
\begin{equation*}
    todo :)
\end{equation*}
Unlike the linear case however, we are not restricted to choosing the $E$ term with respect to the \ac{FOM}/\ac{ROM}.
Instead we can also choose $E^\msc{q} = \id$, or let $E^\msc{q}$ be parametrized alongside $J^\msc{q}, \dots$, and let the fitting algorithm decide on how to compensate for the different choices by affecting the remaining system matrices.

\itodo{discuss the implications of making the $E$ choice here! there has to be a ``correct'' way\dots}

Additionally, the quadratic state does not directly affect the direct feedthrough term.
Instead of inferring the feedthrough in part from the exisiting system components, the procedure can instead compensate potential discrepancies in the state variables by adjusting the feedthrough appropriately.
Finally, this results in the combined system
\begin{equation}\label{eq:combined-quadratic-system}
    \Sigma_\msc{comb} \colon \left\lbrace
    \begin{pmatrix}
        E \dot{x} \\
        E^\msc{q} \dot{q} \\
        y
    \end{pmatrix} = \begin{pmatrix}
        (\hat{J} - \hat{R}) & 0 & (\hat{G} - \hat{P}) \\
        0 & (J^\msc{q} - R^\msc{q}) & (G^\msc{q} - P^\msc{q}) \\
        {(\hat{G} + \hat{P})}\trans & {(G^\msc{q} + P^\msc{q})}\trans & \hat{S} + S^\msc{q} - \hat{N} - N^\msc{q}
    \end{pmatrix} \begin{pmatrix}
        x \\
        q \\
        u
    \end{pmatrix}.
    \right.
\end{equation}

% go back over quadratic data generation (kron, k-r);
% 1: $q$ as quadratic state of $x$;
% 2: think about omitting the quadratic $\dot{x}$ terms;
% 3: consider the option for $E$, do we wnat to choose $\id$ or something else???;
% 4: operators $S, N$ do not need any treatment because they only ever interact with the I/O parts of the model
% mention build up of quadratic model;
% TODO: make sure that the ders are actually the way we want (experiments first?)

The entire algorithm can thus be expressed in four different steps:
\begin{enumerate}
    \item Reduce the \ac{FOM} to get a \ac{ROM},
    \item use the \ac{ROM} to compute the necessary data for fitting the quadratic model,
    \item use the quadratic data to compute a realization of the quadratic sytem, and
    \item add both the \ac{ROM}'s and the quadratic system's outputs to approximate the \ac{FOM}'s behaviour.
\end{enumerate}
The crucial step for this thesis lies in the third step, because many different methods are available, and the user has to choose among them according to the requirements of the model as well as the accessibility of system data.

% mention general outline of the approximation procedure;
% 1: FOM -> ROM;
% 2: ROM -> Quad data;
% 3: Quad data -> QROM;
% 4: QROM + ROM -> combined output;

For our approach we use the \ac{SOBMOR} framework as highlighted at the end of Subsection~\ref{subsec:optimization-based-inference}.
To apply this procedure we have to generate a sequence of $\gamma$ values for the levelling of the \ac{LSQ} objective function.
As hinted at in the description of the \ac{SOBMOR} method, choosing appropriate values of $\gamma$ is essential in obtaining a lower bound for the error term of the approximation, but it also influences the performance of the \ac{SOBMOR} algorithm by stopping the optimization loop early if the $\gamma$ value is large.
For the sake of the upcoming numerical experiments, we use two different approaches: first a fixed sequence of $\gamma$ values, and an adaptive bisection algorithm as described in~\cite{SV2021} as a comparison.
With respect to the initialization of the parametrized matrices $E^\msc{q}(\theta), J^\msc{q}(\theta), R^\msc{q}(\theta), G^\msc{q}(\theta), P^\msc{q}(\theta), N^\msc{q}(\theta), S^\msc{q}(\theta)$

\itodo{this paragraph sounds like it should belong in the numerical experiments section\dots Make sure it is sufficiently unique to justify its placement in this section!}

% mention how gamma sequence was chosen as well as potential changes in optimizers/parameters

It is important to note that the quadratic system matrices cannot just be computed from the linear system matrices.
If we were to imagine a quadratic system obtained from the linear \ac{ROM} by means of Kronecker and Khatri-Rao product, then this system would not be able to contain any more meaningful information than just the linear system on its own because the terms of the linear system have merely been multiplied with eachother without respecting changing dynamics and structural constraints.

\itodo{actually calculate if this is true, does a productified system produce good outputs\textinterrobang}

% discuss bottle necks;
% why not just kron/r-h on system matrices?

As a further idea, we may yet choose to also incorporate quadratic input and output terms alongside the original linear ones into our model.
In this case we have to make sure that we only select the linear terms afterwards when adding to the \ac{ROM}'s output.
However, by thus selecting, we have essentially resolved back to the case in which we only use linear inputs and outputs with the exception of allowing additional information to be passed through the feedback terms.
These feedback terms can however not induce more information, because they only encode the quadratic input information instead of directly affecting the inherent system's state variables.

% mention quadraticized input/output terms
% discussion (potentially after the experiments\dots);
% give recap on theory, lead towards numerical experiments
